# Multi campus  project and workshop - leejeahyuk

1. multi campus science workshop 11.11 ~ 11 13
   1. real estate data 
      1. data :[real estate valuation data](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set)
   2. analysis
      1. [RealEstate01](https://github.com/LeeJeaHyuk/python/blob/master/scikit-learn/RealEstate/README_realestate.md)


# smoking dataset

- [00]Mini_proj_EDA 
  - 주어진 데이터 파일을 불러와서 데이터 프레임으로 저장 데이터 프레임에서 필요한 열을 추출하고, 필요한 열의 이름을 재설정합니다.
  - BMI (체질량 지수)를 계산하고 데이터 프레임에 삽입합니다.
  - 목표 변수 (타겟)로 사용할 'smoking' 열을 추출합니다.
- [01]Mini_proj_dt_obesity
  - 하이퍼파라미터 튜닝
    - `DecisionTreeClassifier` 모델을 생성하고  `GridSearchCV`를 사용하여 파라미터 최적화
    - 3-겹 교차 검증을 수행하며, 결과를 출력하고 모델을 재학습
  - 모델 학습
    - 최적의 하이퍼파라미터를 찾은 후, 학습 데이터 (`X_train`, `y_train`)를 사용하여 모델을 학습
  - 모델 평가
    - 학습된 모델을 사용하여 테스트 데이터 (`X_test`)에 대한 예측을 수행
    - `confusion_matrix` 함수를 사용하여 혼동 행렬 (Confusion Matrix)을 계산하고 출력
    - `scikitplot` 라이브러리를 사용하여 혼동 행렬을 시각화합니다.
    - `classification_report` 함수를 사용하여 정밀도, 재현율, F1 점수 등의 분류 리포트를 생성하고 출력
- [01]Mini_proj_dt_obesity02
  - 데이터 전처리 추가
    - 이전에 주어진 데이터에서 범주형 데이터를 숫자로 변환하고, 데이터를 float 형식으로 변환하고 특정 열 이름을 변경하고 BMI를 계산하여 데이터 프레임에 추가
  - 데이터 스케일링을 추가(StandardScaler)
- [01]Mini_proj_dt_oral
  - 데이터 전처리 
  - 데이터 스케일링
    - StandardScaler, MinMaxScaler, RobustScaler)를 모두 사용하여 데이터를 스케일링 다양한 스케일러를 선택하는 함수 selectscaler()를 만들어 스케일러를 선택하여 적용 가능
  - XGBoost 모델학습
    - early stopping 코드를 추가하여 조금 더 효율적으로 코드 학습
  - 모델 평가
    - 의사 결정 트리와 XGBoost 모델 두 가지를 모두 평가하고, 혼동 행렬 및 분류 리포트를 생성하여 모델 간 성능 비교
- [01]Mini_proj_Ensemble
  - **데이터 불러오기 및 전처리**:
    - 주어진 CSV 파일을 pandas로 불러와서 데이터프레임으로 저장합니다.
    - 범주형 데이터(성별, oral, tartar)를 0과 1로 라벨링합니다.
    - object 형식의 데이터를 float로 변환합니다.
  - **데이터 분할**:
    - 데이터를 훈련 및 테스트 세트로 분할합니다. `train_test_split` 함수를 사용하여 수행하며, 테스트 세트 비율은 20%로 설정되어 있습니다.
  - **모델 훈련 및 평가**:
    - 다양한 머신러닝 모델을 훈련하고 평가합니다. 사용된 모델은 다음과 같습니다:
      - DecisionTreeClassifier
      - RandomForestClassifier
      - XGBoost
      - LGBMClassifier
      - Logistic Regression
      - Support Vector Machine (SVM)
    - 각 모델에 대해 다음을 수행합니다:
      - 모델을 초기화하고 훈련 데이터에 적합시킵니다.
      - 테스트 데이터를 사용하여 모델의 예측을 생성하고, 정확도를 계산합니다.
      - 혼동 행렬(confusion matrix)을 생성하고 시각화합니다.
      - 분류 보고서(classification report)를 출력합니다.
      - 필요한 경우, 모델의 다른 평가 지표를 계산합니다.
  - **앙상블 모델 구축**:
    - 다양한 개별 모델을 조합하여 앙상블 모델을 만듭니다.
    - VotingClassifier를 사용하여 다양한 모델의 소프트 보팅(soft vote)을 수행합니다.
- [01]Mini_proj_module_reportToCSV
  -  데이터 분석 및 머신러닝 모델 평가 결과를 기록하고 관리하기 위한 유틸리티 함수들을 정의
  - **데이터 분석 및 모델 평가 결과 저장**:
    - `test` 함수는 모델의 평가 결과를 데이터프레임 형태로 저장합니다. 이 함수를 사용하여 모델의 평가 지표(Precision, Recall, Accuracy 등)와 모델 이름, 스케일러 이름을 기록합니다.
    - `reportTocsv` 함수는 모델의 평가 결과 데이터프레임을 CSV 파일로 저장합니다. 저장된 파일은 모델의 평가 이력을 관리하고 추후에 결과를 시각화하거나 비교하는 데 사용될 수 있습니다.
  - **하이퍼파라미터 및 모델 성능 저장**:
    - `paramsTocsv` 함수는 모델의 하이퍼파라미터와 성능(최고 점수)을 데이터프레임으로 저장합니다. 이 함수를 사용하여 모델의 하이퍼파라미터와 성능을 기록합니다.
    - 하이퍼파라미터와 성능 정보를 CSV 파일에 저장하여 모델 튜닝 이력을 관리하고, 모델 간의 성능 비교에 활용할 수 있습니다.
  - **폴더 및 파일 관리**:
    - 코드는 결과를 저장할 폴더를 생성하고, 이미 파일이 존재할 경우 이를 업데이트합니다.
    - 시간과 모델 이름, 스케일러 이름 등을 활용하여 파일명을 동적으로 생성하고, 데이터를 누적하여 기록합니다.
- [01]Mini_proj_module02
  - **데이터 전처리 (EDA):** 데이터를 분석하고 변환하는 단계입니다. 주어진 데이터에 대한 초기 탐색(Exploratory Data Analysis)을 수행하며 다음과 같은 작업을 수행합니다:
    - `gender`, `oral`, `tartar`와 같은 범주형 데이터를 0과 1로 라벨링합니다.
    - object 형태의 데이터를 float 형태로 변환합니다.
  - **훈련 (Training):** 다양한 분류 모델을 훈련하고 평가합니다.
    - `DecisionTreeClassifier`
    - `RandomForestClassifier`
    - `XGBoost`
    - `LGBMClassifier`
    - `Logistic Regression`
    - `Support Vector Machine (SVM)`
  - **분류 모델 성능 평가:**
    - 각 모델을 훈련하고, 테스트 데이터를 사용하여 예측합니다.
    - Confusion Matrix(혼동 행렬)를 확인하여 모델의 성능을 시각화하고 평가합니다.
    - Classification Report를 생성하여 정확도, 정밀도, 재현율, F1 스코어 등의 성능 지표를 확인합니다.
  - **모델 상세 설명:**
    - `DecisionTreeClassifier`에 대한 상세 정보를 제공하고 있습니다. `GridSearchCV`를 사용하여 하이퍼파라미터 튜닝을 수행하고 최적의 하이퍼파라미터와 성능을 출력합니다.
    - 최적의 하이퍼파라미터와 성능 지표를 CSV 파일에 저장합니다.
- [01]Mini_proj_rf_obesity
  - 데이터 불러오기 및 전처리:
    - CSV 파일에서 데이터를 읽어와 데이터프레임으로 저장합니다.
    - 성별 (gender), 나이 (age), 키 (height), 몸무게 (weight), 시력 및 청력과 같은 다양한 특성들을 가지고 있습니다.
    - 범주형 데이터를 이진수로 변환합니다. (예: 'F'를 0, 'M'을 1로 변환)
    - 키와 몸무게를 사용하여 BMI (체질량 지수)를 계산합니다.
  - 훈련 및 테스트 데이터 분할:
    - 데이터를 훈련 세트와 테스트 세트로 나눕니다. 일반적으로 데이터의 80%를 훈련에 사용하고 20%를 테스트에 사용합니다.
  - 의사결정 트리 (Decision Tree) 모델 훈련:
    - 의사결정 트리 분류기를 사용하여 모델을 훈련합니다.
    - 그리드 서치 (GridSearchCV)를 사용하여 하이퍼파라미터 튜닝을 수행합니다. 이를 통해 최적의 하이퍼파라미터를 찾습니다.
  - 랜덤 포레스트 (Random Forest) 모델 훈련:
    - 랜덤 포레스트 분류기를 사용하여 모델을 훈련합니다.
    - 훈련 및 테스트 데이터에 대한 정확도를 계산합니다.
  - XGBoost 모델 훈련:
    - XGBoost 분류기를 사용하여 모델을 훈련합니다.
    - 특징 중요도를 시각화합니다.
  - LightGBM 모델 훈련:
    - LightGBM 분류기를 사용하여 모델을 훈련합니다.
    - 조기 정지 (Early Stopping)를 사용하여 과적합을 방지하고 최적의 모델을 선택합니다.
  - 로지스틱 회귀 (Logistic Regression) 모델 훈련:
    - 로지스틱 회귀 분류기를 사용하여 모델을 훈련합니다.
  - 서포트 벡터 머신 (SVM) 모델 훈련:
    - 서포트 벡터 머신 분류기를 사용하여 모델을 훈련합니다.
    - 그리드 서치를 통해 최적의 하이퍼파라미터를 선택합니다.
  - 모델 평가:
    - 각 모델의 성능을 평가하기 위해 정확도, 혼동 행렬, 분류 리포트 등을 사용합니다.
  - 결과 시각화:
    - 모델의 성능 및 중요한 특성에 대한 정보를 시각화하여 분석합니다.



---

## 생성한 모듈

- MyModule
  - `paramsTocsv` 함수
    - **파일 경로 및 이름 설정**: 함수는 데이터 세트 이름(`data_name`), 사용된 스케일러(`scaler`), 모델 이름(`model_name`), 최적 하이퍼파라미터(`best_params`), 그리고 최적 성능 점수(`best_score`)를 매개변수로 받아서 이 정보들로 로그 파일의 경로와 이름 설정
    - **폴더 및 파일 생성 및 관리**: 먼저 `modeldata` 폴더가 존재하지 않으면 생성하고, 로그 파일을 생성합니다. 이 때, 이미 파일이 존재하면 그 파일을 불러와서 내용을 업데이트하고, 파일이 없으면 새로운 파일을 생성합니다.
    - **로그 데이터 업데이트**: 만약 로그 파일이 이미 존재하는 경우, 해당 파일을 읽어서 기존 로그 데이터에 새로운 실험 결과를 추가하고, 그 결과를 다시 파일에 저장합니다. 이로써 여러 번의 실험 결과를 하나의 파일에 누적하여 저장할 수 있습니다.
    - **시간 정보 추가**: 각 실험의 실행 시간(날짜와 시간)을 기록하여 실험의 일련 번호와 함께 저장합니다. 이를 통해 언제 어떤 실험이 수행되었는지를 추적할 수 있습니다.
  - `selectparam` 함수
    - **모델 하이퍼파라미터 및 성능 데이터 검색**: 이 함수는 주어진 `csv_name`과 `index`를 기반으로 모델 하이퍼파라미터 및 성능 데이터를 검색합니다. `csv_name`은 모델 성능과 하이퍼파라미터가 저장된 CSV 파일의 이름을 나타내며, `index`는 원하는 실험 결과의 인덱스를 나타냅니다.
    - **CSV 파일 읽기**: 함수는 주어진 `csv_name`을 사용하여 해당 파일을 읽어서 데이터프레임으로 변환합니다.
    - **데이터 전처리 및 필터링**: 데이터프레임에서 지정된 `index`에 해당하는 행을 선택하고, 누락된 열을 제거합니다. 따라서 해당 실험 결과의 하이퍼파라미터와 그에 따른 성능 지표만을 포함하는 사전(dict)을 생성합니다.
    - **불필요한 열 제거**: 생성된 사전(dict)에서 특정 열(예: 'date', 'data_name', 'scaler', 'best_score')을 제거합니다. 이러한 열은 주로 로깅 시간 또는 데이터 세트 이름과 같은 보조 정보를 포함하고 있으며, 주로 하이퍼파라미터와 관련이 없습니다.
    - **결과 반환**: 최종적으로 선택된 실험 결과의 하이퍼파라미터와 성능 지표가 포함된 사전(dict)을 반환합니다.
